Product Requirements Document: Project Helios v0.9.0 - "The Agent"

Document Version: 2.1 (Proofread & Corrected)
Status: Approved for Refactoring
Target Version: 0.9.0
Theme: "Metacognition & Persistence"

## 1. Vision & Justification

### 1.1 Vision
Transform Helios from a stateless analysis tool into an intelligent agent with persistent memory. The system must not only perform calculations but also remember how it was trained, recall its knowledge on demand, and provide transparent insights into its own learning process.

### 1.2 Justification for Refactoring
The current v0 (MVP) architecture is stateless: each run is isolated. This prevents comparing models over time and gaining deeper insights into the learning process. This refactoring introduces Journaling, Remembering, and Reflecting—foundational concepts required for future advanced work (Levels 2 and 3).

## 2. Goals & Objectives for v0.9.0

- **Primary Goal:** Refactor Helios to save, load, and manage trained models and their metadata.
- **Technical Goal:** Implement a standardized system for storing model artifacts (`.pth`) and training logs (`.json`).
- **User Goal:** Enhance the React UI to allow: 1) training new models, 2) loading existing models for analysis, and 3) visualizing learning history (loss curves).
- **Strategic Goal:** Enable the "Ensemble of Specialists" strategy within the application's architecture.

## 3. Refactored Scope & Features

### Feature 1: Model Training Mission (Refactored)
**Description:** Introduce a new mission in the React UI to train probabilistic models.

**Requirements:**
1. UI fields for model name (e.g., `modern_era_v1`), epochs, and learning rate.
2. Backend `Trainer` class handles training.
3. On completion, the backend must save two artifacts in `./models/`:
   - `modern_era_v1.pth` (model weights)
   - `modern_era_v1.json` (training journal)
4. The JSON journal must include:
   - `model_name`
   - `timestamp` (ISO 8601 format)
   - `training_data_source` (e.g., CSV file name and row count)
   - `date_range_trained` (if applicable)
   - `epochs`
   - `learning_rate`
   - `loss_history` (array of losses per epoch)

### Feature 2: Model Management System (New)
**Description:** Organize and access agent "brains."

**Requirements:**
1. Scan `./models/` directory on startup to discover `.pth` files.
2. Populate the React UI dropdown with discovered models plus a "Random" option.
3. When a model is selected, backend loads the corresponding `.pth` for inference/backtesting.

### Feature 3: Metacognitive UI (New)
**Description:** UI for reflecting on a model's learning process.

**Requirements:**
1. In the results panel, add a "Reflect" or "Model Insights" tab.
2. On backtest completion with a trained model, enable the tab.
3. Backend loads the `.json` journal for the selected model.
4. Display key metadata (training date, epochs, etc.).
5. Render an interactive loss curve chart using the journal's `loss_history`.

### Feature 4: Unified Memory Store & Reflection Engine (New)
**Description:** Implement a single, lightweight embedded database that stores all model journals in separate namespaces, enabling both per‑model isolation and cross‑model analytics.

**Requirements:**
1. **Embedded DB Selection:** Use SQLite (or equivalent) as the unified store at `./models/helios_memory.db`.
2. **Per-Model Namespaces:** In the DB, create one table per model (e.g., `journal_modern_era_v1`) or use a single `journal_entries` table with a `model_name` column.
3. **Journal Write API:** During any mission, backend writes entries into the DB:
   - **Training Events:** Insert rows with fields: `model_name`, `event_type` (`training_start`, `training_end`), `timestamp`, `metadata` (JSON blob including hyperparameters, data source).
   - **Backtest Events:** Insert rows: `model_name`, `event_type` (`backtest_run`), `timestamp`, `metadata` (JSON blob summarizing performance).
   - **Inference Events:** (Future) Insert rows: `model_name`, `event_type` (`inference`), `timestamp`, `metadata` (JSON blob with input/output).
4. **Journal Read API:** Expose `/api/journal?model=<model_name>&[start]&[end]&[type]` that queries the DB and returns filtered entries in chronological order.
5. **Cross-Model Queries:** Allow `/api/journal?all=true` to fetch entries across all models for global analytics.
6. **UI Integration:**
   - Under the "Model Insights" tab, add:
     - **Memory Log Viewer:** a paginated list of entries with filters by model, event type, and date range.
     - **Reflection Dashboard:** a summary card computing:
       - Total training epochs (sum of `training_end` entries).
       - Average loss improvement per session (requires augmenting metadata with before/after loss values).
       - Performance trend chart combining backtest metrics across models.
7. **Archival & Maintenance:**
   - Implement a background compaction task (e.g., monthly) to archive old entries into a compressed JSON file and delete from the DB to maintain performance.
   - Provide admin endpoint `/api/compact-memory` to trigger archiving.

## 4. Seed Code for Refactoring Seed Code for Refactoring

### 4.1 Backend: `agent.py`
```python
import random
import torch
import torch.nn as nn
import os

MODEL_DIR = "models"

class PowerballNet(nn.Module):
    def __init__(self):
        super(PowerballNet, self).__init__()
        # Example architecture; adjust feature size as needed
        self.fc1 = nn.Linear(in_features=10, out_features=128)
        self.relu = nn.ReLU()
        self.output_wb = nn.Linear(128, 69)
        self.output_pb = nn.Linear(128, 26)

    def forward(self, x):
        x = self.relu(self.fc1(x))
        return self.output_wb(x), self.output_pb(x)


def generate_random_ticket():
    """Generates a random Powerball ticket."""
    white = sorted(random.sample(range(1, 70), 5))
    pb = random.randint(1, 26)
    return white, pb

class MLPowerballAgent:
    def __init__(self, model_name: str):
        self.model_name = model_name
        self.model = PowerballNet()
        self.model_path = os.path.join(MODEL_DIR, f"{model_name}.pth")

    def load_model(self):
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"Model not found: {self.model_path}")
        self.model.load_state_dict(torch.load(self.model_path))
        self.model.eval()

    def predict_ticket(self):
        # TODO: Replace placeholder with real inference logic
        return generate_random_ticket()
```

### 4.2 Backend: `trainer.py`
```python
import os
import time
import json
import random
import torch
import torch.nn as nn
import torch.optim as optim
from agent import PowerballNet

MODEL_DIR = "models"

class Trainer:
    def __init__(
        self,
        model_name: str,
        dataframe,
        epochs: int,
        learning_rate: float
    ):
        self.model_name = model_name
        self.df = dataframe
        self.epochs = epochs
        self.lr = learning_rate
        self.model = PowerballNet()
        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)
        self.criterion = nn.CrossEntropyLoss()

    def train(self) -> list:
        loss_history = []
        for epoch in range(1, self.epochs + 1):
            # TODO: Implement real training loop
            simulated_loss = 1.0 / epoch + random.uniform(-0.05, 0.05)
            loss_history.append(simulated_loss)
            print(f"Epoch {epoch}/{self.epochs}, Loss: {simulated_loss:.4f}")
            time.sleep(0.1)
        self._save_artifacts(loss_history)
        return loss_history

    def _save_artifacts(self, loss_history: list):
        os.makedirs(MODEL_DIR, exist_ok=True)
        # Save model
        path = os.path.join(MODEL_DIR, f"{self.model_name}.pth")
        torch.save(self.model.state_dict(), path)
        # Save journal
        journal = {
            "model_name": self.model_name,
            "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
            "training_data_source": f"CSV with {len(self.df)} rows",
            "epochs": self.epochs,
            "learning_rate": self.lr,
            "loss_history": loss_history
        }
        with open(os.path.join(MODEL_DIR, f"{self.model_name}.json"), 'w') as f:
            json.dump(journal, f, indent=4)
```
